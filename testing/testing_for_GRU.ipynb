{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXqy4WU5_CRM",
        "outputId": "1d7935ed-419f-413f-fa4a-825108c8d647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hQkiIPT-95a",
        "outputId": "90d699b0-2482-4315-cdd1-ae0c10ca115f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ wrote 365 rows → /content/drive/MyDrive/meteo_2023_last6h.csv\n"
          ]
        }
      ],
      "source": [
        "# ▶ Cell X: Build nearest-neighbor 6-h features for 2023\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# 1) paths – adjust to your Drive\n",
        "SRC = Path(\"/content/drive/MyDrive/preof2023.csv\")\n",
        "DST = Path(\"/content/drive/MyDrive/meteo_2023_last6h.csv\")\n",
        "\n",
        "# 2) variables (in your CSV)\n",
        "vars = [\n",
        "    \"air_temp_C\",\n",
        "    \"dew_point_C\",\n",
        "    \"relative_humidity_percent\",\n",
        "    \"wind_speed_m_s\",\n",
        "    \"precipitation_in\"\n",
        "]\n",
        "\n",
        "# 3) load & prepare\n",
        "df = pd.read_csv(SRC, parse_dates=['datetime'])\n",
        "df['date'] = df['datetime'].dt.date\n",
        "\n",
        "rows = []\n",
        "for day, grp in df.groupby('date'):\n",
        "    grp = grp.sort_values('datetime')\n",
        "    row = {'date': day}\n",
        "\n",
        "    # for each lag = 5 → 0\n",
        "    for lag in range(5, -1, -1):\n",
        "        target = pd.Timestamp(day) + pd.Timedelta(hours=10 - lag)\n",
        "\n",
        "        # find nearest timestamp in grp\n",
        "        diffs = (grp['datetime'] - target).abs()\n",
        "        idx   = diffs.idxmin()\n",
        "        rec   = grp.loc[idx]\n",
        "\n",
        "        # record each variable\n",
        "        for v in vars:\n",
        "            row[f\"{v}_t-{lag}h\"] = rec[v]\n",
        "\n",
        "    rows.append(row)\n",
        "\n",
        "# 4) assemble & save\n",
        "feat_df = pd.DataFrame(rows)\n",
        "feat_df.to_csv(DST, index=False)\n",
        "print(f\"✅ wrote {len(feat_df)} rows → {DST}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1 ▶ Imports & Test DataLoader\n",
        "import os, math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from tifffile import imread\n",
        "\n",
        "# ▶ point to your test CSV + patches folder\n",
        "TEST_CSV     = \"/content/drive/MyDrive/meteo_2023_last6h.csv\"\n",
        "PATCHES_DIR  = \"/content/drive/MyDrive/test_patches\"\n",
        "\n",
        "# ▶ read & pick only the 6-h lag cols\n",
        "df_test = pd.read_csv(TEST_CSV, parse_dates=['date'])\n",
        "seq_cols = [c for c in df_test.columns if \"_t-\" in c]\n",
        "\n",
        "class LSTTestDataset(Dataset):\n",
        "    def __init__(self, df, patches_dir, seq_cols, n_hours=6):\n",
        "        self.df          = df.reset_index(drop=True)\n",
        "        self.patches_dir = patches_dir\n",
        "        self.seq_cols    = seq_cols\n",
        "        self.n_hours     = n_hours\n",
        "        self.n_vars      = len(seq_cols)//n_hours\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.loc[i]\n",
        "        arr = imread(os.path.join(self.patches_dir, row[\"patch_filename\"])).astype(np.float32)\n",
        "        img = torch.from_numpy(arr[[1,2,3]]).float()    # [3,H,W]\n",
        "        tar = torch.from_numpy(arr[0]).unsqueeze(0).float()  # [1,H,W]\n",
        "        w_flat = row[self.seq_cols].values.astype(np.float32)\n",
        "        w_seq  = torch.from_numpy(w_flat).view(self.n_hours, self.n_vars)\n",
        "        return img, w_seq, tar\n",
        "\n",
        "test_ds = LSTTestDataset(df_test, PATCHES_DIR, seq_cols)\n",
        "test_loader = DataLoader(test_ds, batch_size=4, shuffle=False, num_workers=0, pin_memory=False)\n",
        "print(\"Test samples:\", len(test_ds), \"→ Batches:\", len(test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8S7gPaRCGda",
        "outputId": "d88bd8c2-b5f5-45f8-b294-1a444f2b7594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test samples: 365 → Batches: 92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 ▶ Model definition (ViT+GRU variant)\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "class PretrainedViTLSTModel(nn.Module):\n",
        "    def __init__(self, weather_dim=5, hidden_dim=768,\n",
        "                 vit_name=\"vit_base_patch16_224\",\n",
        "                 num_layers=2, num_heads=8):\n",
        "        super().__init__()\n",
        "        self.vit = timm.create_model(vit_name, pretrained=False, num_classes=0)\n",
        "        self.weather_encoder = nn.GRU(input_size=weather_dim,\n",
        "                                      hidden_size=hidden_dim,\n",
        "                                      batch_first=True)\n",
        "        enc = nn.TransformerEncoderLayer(d_model=hidden_dim,\n",
        "                                         nhead=num_heads,\n",
        "                                         dim_feedforward=hidden_dim*4,\n",
        "                                         dropout=0.1)\n",
        "        self.transformer = nn.TransformerEncoder(enc, num_layers)\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(hidden_dim, hidden_dim//2, 2,2),\n",
        "            nn.BatchNorm2d(hidden_dim//2), nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(hidden_dim//2, hidden_dim//4, 2,2),\n",
        "            nn.BatchNorm2d(hidden_dim//4), nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(hidden_dim//4, 1, 2,2),\n",
        "        )\n",
        "    def forward(self, x, w_seq):\n",
        "        feats   = self.vit.forward_features(x)       # [B,197,768]\n",
        "        cls_tok = feats[:, :1]                       # [B,1,768]\n",
        "        patch_t = feats[:, 1:]                       # [B,196,768]\n",
        "        _, h_n  = self.weather_encoder(w_seq)        # [1,B,768]\n",
        "        w_tok   = h_n.squeeze(0).unsqueeze(1)        # [B,1,768]\n",
        "        tokens  = torch.cat([patch_t, w_tok, cls_tok],1)\n",
        "        t       = self.transformer(tokens.permute(1,0,2)).permute(1,0,2)\n",
        "        out_tok = t[:, :-2, :]                       # [B,196,768]\n",
        "        B,N,D    = out_tok.shape\n",
        "        G        = int(math.sqrt(N))\n",
        "        x_small  = out_tok.transpose(1,2).view(B,D,G,G)\n",
        "        return self.deconv(x_small)                  # [B,1,224,224]"
      ],
      "metadata": {
        "id": "fM5m6xTvCadU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 ▶ Load checkpoint & Evaluate RMSE\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model  = PretrainedViTLSTModel(weather_dim=5).to(device)\n",
        "\n",
        "# load the last checkpoint\n",
        "ckpt = torch.load(\"/content/drive/MyDrive/Model_vit_gru_Checkpoints/vit_gru_epoch10.pt\",\n",
        "                  map_location=device)\n",
        "model.load_state_dict(ckpt['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "mse = nn.MSELoss(reduction='sum')\n",
        "total_loss = 0.0\n",
        "total_pixels = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, w_seq, tars in test_loader:\n",
        "        imgs, w_seq, tars = imgs.to(device), w_seq.to(device), tars.to(device)\n",
        "        preds = model(imgs, w_seq)\n",
        "        total_loss   += mse(preds, tars).item()\n",
        "        total_pixels += imgs.size(0) * preds.size(2) * preds.size(3)\n",
        "\n",
        "rmse = math.sqrt(total_loss / total_pixels)\n",
        "print(f\"Test RMSE (per pixel): {rmse:.3f}°C\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "-LUrqsB0Cf52",
        "outputId": "e97162d1-87f3-481b-b9bb-604e81f8f9f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Model_vit_gru_Checkpoints/vit_gru_epoch10.pt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6155e18b3bfa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# load the last checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m ckpt = torch.load(\"/content/drive/MyDrive/Model_vit_gru_Checkpoints/vit_gru_epoch10.pt\",\n\u001b[0m\u001b[1;32m      9\u001b[0m                   map_location=device)\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Model_vit_gru_Checkpoints/vit_gru_epoch10.pt'"
          ]
        }
      ]
    }
  ]
}