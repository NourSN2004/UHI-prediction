{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCmh74JmKDRT",
        "outputId": "bcec166a-65d1-46a7-a64f-3552daa9e2d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 0) Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_aj20zmKTT9",
        "outputId": "6d27e34a-1ccd-4aa0-c815-af5e9f7a56ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Imports\n",
        "import os, math, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "from tifffile import imread\n",
        "from torch.cuda.amp import autocast, GradScaler"
      ],
      "metadata": {
        "id": "q-HOZMaRKJ5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imagecodecs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S0jEjwcnpU7",
        "outputId": "2cba396e-b93f-4bc8-8a76-53e79a3afbcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imagecodecs\n",
            "  Downloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imagecodecs) (2.0.2)\n",
            "Downloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imagecodecs\n",
            "Successfully installed imagecodecs-2025.3.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Cached dataset that loads each TIFF once into RAM\n",
        "class CachedLSTDataset(Dataset):\n",
        "    def __init__(self, df, patches_dir, weather_cols,\n",
        "                 transform, target_size=(56,56)):\n",
        "        self.transform    = transform\n",
        "        self.weather_cols = weather_cols\n",
        "        self.target_size  = target_size\n",
        "\n",
        "        self.raw      = []\n",
        "        self.targets  = []\n",
        "        self.weathers = []\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            arr = imread(os.path.join(patches_dir, row[\"filename\"])).astype(np.float32)\n",
        "            # store raw 4×H×W array\n",
        "            self.raw.append(arr)\n",
        "            # pre‐store target band\n",
        "            t = torch.tensor(arr[0], dtype=torch.float32).unsqueeze(0)\n",
        "            self.targets.append(t)\n",
        "            # pre‐store weather vector\n",
        "            w = row[self.weather_cols].values.astype(np.float32)\n",
        "            self.weathers.append(torch.from_numpy(w))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.raw)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        arr = self.raw[idx]\n",
        "        # build RGB image, apply transform\n",
        "        img_np = arr[[1,2,3]].transpose(1,2,0).astype(np.uint8)\n",
        "        img    = self.transform(img_np)               # [3,224,224]\n",
        "        # resize target\n",
        "        tgt = F.interpolate(self.targets[idx].unsqueeze(0),\n",
        "                            size=self.target_size,\n",
        "                            mode='bilinear',\n",
        "                            align_corners=False\n",
        "                           ).squeeze(0)               # [1,56,56]\n",
        "        weather = self.weathers[idx]                   # [meteo_dim]\n",
        "        return img, weather, tgt"
      ],
      "metadata": {
        "id": "KOfL_t-EKalF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Which meteorological columns?\n",
        "weather_cols = [\n",
        "    \"air_temp_C\",\n",
        "    \"dew_point_C\",\n",
        "    \"relative_humidity_percent\",\n",
        "    \"wind_speed_m_s\",\n",
        "    \"precipitation_in\",\n",
        "]\n",
        "\n",
        "# 2) Load & clean CSV\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/PatchedOutput/patch_with_meteo.csv\")\n",
        "for c in weather_cols:\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# drop any row missing weather data or patch_filename\n",
        "df = df.dropna(subset=weather_cols + [\"patch_filename\"]).reset_index(drop=True)\n",
        "print(f\"Using {len(df)} samples after dropna\")\n",
        "\n",
        "# 3) Define cached Dataset\n",
        "class CachedLSTDataset(Dataset):\n",
        "    def __init__(self, df, patches_dir, weather_cols,\n",
        "                 transform, target_size=(56,56)):\n",
        "        self.transform    = transform\n",
        "        self.weather_cols = weather_cols\n",
        "        self.target_size  = target_size\n",
        "\n",
        "        self.raw      = []\n",
        "        self.targets  = []\n",
        "        self.weathers = []\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            # load once\n",
        "            arr = imread(os.path.join(patches_dir, row[\"patch_filename\"])).astype(np.float32)\n",
        "            self.raw.append(arr)\n",
        "\n",
        "            # pre-store full-res target\n",
        "            t = torch.tensor(arr[0], dtype=torch.float32).unsqueeze(0)\n",
        "            self.targets.append(t)\n",
        "\n",
        "            # pre-store weather vector\n",
        "            w = row[self.weather_cols].values.astype(np.float32)\n",
        "            self.weathers.append(torch.from_numpy(w))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.raw)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        arr     = self.raw[idx]\n",
        "        img_np  = arr[[1,2,3]].transpose(1,2,0).astype(np.uint8)\n",
        "        img     = self.transform(img_np)               # [3,224,224]\n",
        "\n",
        "        tgt     = F.interpolate(\n",
        "                    self.targets[idx].unsqueeze(0),\n",
        "                    size=self.target_size,\n",
        "                    mode='bilinear',\n",
        "                    align_corners=False\n",
        "                  ).squeeze(0)                         # [1,56,56]\n",
        "\n",
        "        weather = self.weathers[idx]                   # [5]\n",
        "        return img, weather, tgt\n",
        "\n",
        "# 4) Instantiate dataset & loaders\n",
        "patches_dir = \"/content/drive/MyDrive/PatchedOutput_Cleaned\"\n",
        "transform   = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485,0.456,0.406],\n",
        "        std =[0.229,0.224,0.225],\n",
        "    ),\n",
        "])\n",
        "\n",
        "dataset = CachedLSTDataset(df, patches_dir, weather_cols,\n",
        "                           transform, target_size=(56,56))\n",
        "\n",
        "n_train    = int(0.8 * len(dataset))\n",
        "train_ds, val_ds = random_split(dataset, [n_train, len(dataset)-n_train])\n",
        "\n",
        "train_dl = DataLoader(train_ds,\n",
        "                      batch_size=16,\n",
        "                      shuffle=True,\n",
        "                      num_workers=4,\n",
        "                      pin_memory=True,\n",
        "                      persistent_workers=True)\n",
        "\n",
        "val_dl   = DataLoader(val_ds,\n",
        "                      batch_size=16,\n",
        "                      shuffle=False,\n",
        "                      num_workers=4,\n",
        "                      pin_memory=True,\n",
        "                      persistent_workers=True)\n",
        "\n",
        "print(f\"Train samples: {len(train_ds)}, Val samples: {len(val_ds)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CScIMkzbneVQ",
        "outputId": "803a1a6c-7c87-4161-f91c-2d34a221698b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 18813 samples after dropna\n",
            "Train samples: 15050, Val samples: 3763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Model definition\n",
        "class CNN_MLP(nn.Module):\n",
        "    def __init__(self, meteo_dim, H, W):\n",
        "        super().__init__()\n",
        "        # spatial encoder\n",
        "        self.cnn = models.resnet18(pretrained=True)\n",
        "        for name, p in self.cnn.named_parameters():\n",
        "            if not (name.startswith('layer4') or name.startswith('fc')):\n",
        "                p.requires_grad = False\n",
        "        self.cnn.conv1 = nn.Conv2d(3,64,7,2,3)\n",
        "        self.cnn.fc    = nn.Identity()  # outputs 512\n",
        "\n",
        "        # weather MLP\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(meteo_dim,16), nn.ReLU(),\n",
        "            nn.Linear(16,16),        nn.ReLU()\n",
        "        )\n",
        "        # fusion head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(512+16,512), nn.ReLU(),\n",
        "            nn.Linear(512, H*W)\n",
        "        )\n",
        "        self.H, self.W = H, W\n",
        "\n",
        "    def forward(self, x, m):\n",
        "        f = self.cnn(x)                   # [B,512]\n",
        "        w = self.mlp(m)                   # [B,16]\n",
        "        h = torch.cat([f,w], dim=1)       # [B,528]\n",
        "        out = self.head(h)                # [B,H*W]\n",
        "        return out.view(-1,1,self.H,self.W)  # [B,1,H,W]"
      ],
      "metadata": {
        "id": "XWA9wlWhnngM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Instantiate model, optimizer, loss, scaler\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "_,C,H,W = next(iter(train_dl))[0].shape  # get H,W from sample if needed\n",
        "meteo_dim = len(weather_cols)\n",
        "\n",
        "model  = CNN_MLP(meteo_dim, 56, 56).to(device)\n",
        "opt    = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "lossf  = nn.MSELoss()\n",
        "scaler = GradScaler()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR3RcVs0oPvE",
        "outputId": "8d9e9c0c-f60b-44d5-86e1-810bd0c939f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-16-51891584cc56>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Training loop with mixed precision\n",
        "num_epochs = 10\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    # — Train —\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for x, m, y in train_dl:\n",
        "        x,m,y = x.to(device), m.to(device), y.to(device)\n",
        "        opt.zero_grad()\n",
        "        with autocast():\n",
        "            pred = model(x, m)\n",
        "            loss = lossf(pred, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item() * x.size(0)\n",
        "    train_rmse = math.sqrt(running_loss / len(train_dl.dataset))\n",
        "\n",
        "    # — Validate —\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, m, y in val_dl:\n",
        "            x,m,y = x.to(device), m.to(device), y.to(device)\n",
        "            with autocast():\n",
        "                pred = model(x, m)\n",
        "                loss = lossf(pred, y)\n",
        "            val_loss += loss.item() * x.size(0)\n",
        "    val_rmse = math.sqrt(val_loss / len(val_dl.dataset))\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} ▶ Train RMSE: {train_rmse:.3f} | Val RMSE: {val_rmse:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nzA-H8eoUJS",
        "outputId": "bb768551-fbc4-4d28-b585-bc8bcbdc474e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-655e30a7e51a>:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "<ipython-input-17-655e30a7e51a>:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 ▶ Train RMSE: 4.406 | Val RMSE: 2.539\n",
            "Epoch 02 ▶ Train RMSE: 2.019 | Val RMSE: 2.760\n",
            "Epoch 03 ▶ Train RMSE: 1.801 | Val RMSE: 1.794\n",
            "Epoch 04 ▶ Train RMSE: 1.695 | Val RMSE: 2.491\n",
            "Epoch 05 ▶ Train RMSE: 1.709 | Val RMSE: 1.496\n",
            "Epoch 06 ▶ Train RMSE: 1.496 | Val RMSE: 2.784\n",
            "Epoch 07 ▶ Train RMSE: 1.462 | Val RMSE: 3.352\n",
            "Epoch 08 ▶ Train RMSE: 1.380 | Val RMSE: 1.291\n",
            "Epoch 09 ▶ Train RMSE: 1.316 | Val RMSE: 1.436\n",
            "Epoch 10 ▶ Train RMSE: 1.247 | Val RMSE: 2.012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imagecodes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p98-KhJjT8-I",
        "outputId": "835a0ca3-1439-47a3-df74-9f7f9d738378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imagecodes\n",
            "  Downloading imagecodes-0.0.1-py3-none-any.whl.metadata (576 bytes)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from imagecodes) (11.1.0)\n",
            "Downloading imagecodes-0.0.1-py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: imagecodes\n",
            "Successfully installed imagecodes-0.0.1\n"
          ]
        }
      ]
    }
  ]
}