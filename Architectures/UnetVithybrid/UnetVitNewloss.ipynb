{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-XOtdxeDQQe",
        "outputId": "80588b51-aede-491f-8c85-7b4c7dcf3cd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (2025.3.30)\n",
            "Collecting imagecodecs\n",
            "  Downloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.30.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
            "Downloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imagecodecs\n",
            "Successfully installed imagecodecs-2025.3.30\n"
          ]
        }
      ],
      "source": [
        "# In your setup cell (Cell 1), after mounting drive:\n",
        "!pip install timm torchvision tifffile imagecodecs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACJwQ2lFtnjN",
        "outputId": "a6e9d14d-6316-4c0b-d073-0ab3e543ce27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHHZtfCX_iSZ",
        "outputId": "02fc1257-0a22-4eb5-b9e4-607d4e38b160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (2025.3.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.30.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Mount Drive & install\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install timm torchvision tifffile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vjYLXjgylgR"
      },
      "outputs": [],
      "source": [
        "# Cell 2 ▶ Consolidated imports\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import timm\n",
        "from torchvision import transforms, models\n",
        "\n",
        "from tifffile import imread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5ecPwHOAwwf"
      },
      "outputs": [],
      "source": [
        "# Cell 1 ▶ Dataset (224×224 targets, no down-scaling)\n",
        "class LSTDataset(Dataset):\n",
        "    def __init__(self, df, patches_dir, weather_cols):\n",
        "        self.df           = df.reset_index(drop=True)\n",
        "        self.patches_dir  = patches_dir\n",
        "        self.weather_cols = weather_cols\n",
        "        self.transform    = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((224, 224)),          # resize image\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std =[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row  = self.df.loc[idx]\n",
        "        arr  = imread(os.path.join(self.patches_dir, row[\"filename\"])\n",
        "                     ).astype(np.float32)            # (4,H,W)\n",
        "\n",
        "        # --- inputs -------------------------------------------------\n",
        "        img_np = arr[[1,2,3]].transpose(1,2,0).astype(np.uint8)\n",
        "        img    = self.transform(img_np)              # [3,224,224]\n",
        "\n",
        "        # --- target (LST) at *full* 224×224 --------------------------\n",
        "        lst    = arr[0]                              # (H,W)\n",
        "        lst    = torch.tensor(lst, dtype=torch.float32).unsqueeze(0)\n",
        "        lst    = F.interpolate(lst.unsqueeze(0), size=(224,224),\n",
        "                               mode='bilinear', align_corners=False\n",
        "                              ).squeeze(0)           # [1,224,224]\n",
        "\n",
        "        # --- meteorology vector -------------------------------------\n",
        "        weather = torch.tensor(\n",
        "            row[self.weather_cols].values.astype(np.float32)\n",
        "        )\n",
        "        return img, weather, lst\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5ctE8VvyujF"
      },
      "outputs": [],
      "source": [
        "# define which meteorological columns to pull\n",
        "weather_cols = [\n",
        "    \"air_temp_C\",\n",
        "    \"dew_point_C\",\n",
        "    \"relative_humidity_percent\",\n",
        "    \"wind_speed_m_s\",\n",
        "    \"precipitation_in\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDH7hrDJA3Rv"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/PatchedOutput/tiff_with_meteo.csv\")\n",
        "for col in weather_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "df = df.dropna(subset=weather_cols + [\"filename\"]).reset_index(drop=True)\n",
        "\n",
        "patches_dir = \"/content/drive/MyDrive/PatchedOutput_Cleaned\"\n",
        "dataset     = LSTDataset(df, patches_dir, weather_cols)\n",
        "train_sz    = int(0.8 * len(dataset))\n",
        "val_sz      = len(dataset) - train_sz\n",
        "train_ds, val_ds = random_split(dataset, [train_sz, val_sz])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  num_workers=0, pin_memory=False)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, num_workers=0, pin_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AlmmZkxbAZG"
      },
      "outputs": [],
      "source": [
        "# ─── Cell 4: VIT-UNET MODEL DEFINITION ───────────────────────────────────────────\n",
        "class ViTUNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, weather_dim=5, base_channels=64,\n",
        "                 num_heads=8, trans_layers=2, trans_dim=512):\n",
        "        super().__init__()\n",
        "        def conv_block(in_ch, out_ch):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True)\n",
        "            )\n",
        "        # Encoder\n",
        "        self.conv1 = conv_block(in_channels, base_channels)\n",
        "        self.conv2 = conv_block(base_channels, base_channels*2)\n",
        "        self.conv3 = conv_block(base_channels*2, base_channels*4)\n",
        "        self.conv4 = conv_block(base_channels*4, base_channels*8)\n",
        "        self.conv5 = conv_block(base_channels*8, base_channels*8)\n",
        "        self.pool  = nn.MaxPool2d(2)\n",
        "        # Weather projection\n",
        "        self.weather_proj = nn.Linear(weather_dim, trans_dim)\n",
        "        # Bottleneck + Transformer\n",
        "        self.bottleneck_proj = nn.Conv2d(base_channels*8, trans_dim, 1)\n",
        "        self.pos_embed       = nn.Parameter(torch.zeros(1, 14*14, trans_dim))\n",
        "        self.weather_token   = nn.Parameter(torch.zeros(1,1,trans_dim))\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=trans_dim, nhead=num_heads,\n",
        "            dim_feedforward=trans_dim*4, dropout=0.1, batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=trans_layers)\n",
        "        # Decoder\n",
        "        self.up4 = nn.ConvTranspose2d(trans_dim,     base_channels*8, 2,2)\n",
        "        self.up3 = nn.ConvTranspose2d(base_channels*8, base_channels*4, 2,2)\n",
        "        self.up2 = nn.ConvTranspose2d(base_channels*4, base_channels*2, 2,2)\n",
        "        self.up1 = nn.ConvTranspose2d(base_channels*2, base_channels,   2,2)\n",
        "        self.dec4 = conv_block(base_channels*8 + base_channels*8, base_channels*8)\n",
        "        self.dec3 = conv_block(base_channels*4 + base_channels*4, base_channels*4)\n",
        "        self.dec2 = conv_block(base_channels*2 + base_channels*2, base_channels*2)\n",
        "        self.dec1 = conv_block(base_channels   + base_channels,   base_channels)\n",
        "        self.final_conv = nn.Conv2d(base_channels, 1, 1)\n",
        "\n",
        "    def forward(self, x, weather):\n",
        "        B,C,H,W = x.shape\n",
        "        e1 = self.conv1(x)\n",
        "        e2 = self.conv2(self.pool(e1))\n",
        "        e3 = self.conv3(self.pool(e2))\n",
        "        e4 = self.conv4(self.pool(e3))\n",
        "        e5 = self.conv5(self.pool(e4))\n",
        "\n",
        "        bt      = self.bottleneck_proj(e5)\n",
        "        N       = bt.shape[2]*bt.shape[3]\n",
        "        bt_flat = bt.view(B, bt.shape[1], N).permute(0,2,1)\n",
        "        bt_pos  = bt_flat + self.pos_embed[:, :N, :]\n",
        "        w_tok   = self.weather_proj(weather).unsqueeze(1) + self.weather_token\n",
        "        trans   = torch.cat([bt_pos, w_tok], dim=1)\n",
        "        out_t   = self.transformer(trans)\n",
        "        spat    = out_t[:, :-1, :]\n",
        "        fs      = int(math.sqrt(spat.size(1)))\n",
        "        f_ts    = spat.permute(0,2,1).view(B, bt.shape[1], fs, fs)\n",
        "\n",
        "        d4 = self.dec4(torch.cat([self.up4(f_ts), e4], dim=1))\n",
        "        d3 = self.dec3(torch.cat([self.up3(d4),  e3], dim=1))\n",
        "        d2 = self.dec2(torch.cat([self.up2(d3),  e2], dim=1))\n",
        "        d1 = self.dec1(torch.cat([self.up1(d2),  e1], dim=1))\n",
        "        return self.final_conv(d1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04CMRl-7aEkA",
        "outputId": "cdfbbeb9-5ec5-4787-c0fe-5784f8f7255b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model, SmoothL1Loss, optimizer & scheduler ready\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "<ipython-input-33-3411cbb376b4>:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# ─── Cell 5: INITIALIZE MODEL, SmoothL1Loss, OPTIMIZER & LR SCHEDULER ─────────\n",
        "device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model     = ViTUNet(in_channels=3, weather_dim=len(weather_cols)).to(device)\n",
        "\n",
        "# Use SmoothL1 (Huber) loss instead of MSE\n",
        "loss_fn = nn.SmoothL1Loss()\n",
        "\n",
        "# Optimizer: only on parameters that require grad\n",
        "opt = torch.optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-2\n",
        ")\n",
        "\n",
        "# Reduce LR on plateau of validation loss\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    opt,\n",
        "    mode='min',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "scaler = GradScaler()\n",
        "\n",
        "print(\"✅ Model, SmoothL1Loss, optimizer & scheduler ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8ekPydVA5l-",
        "outputId": "9f2d961e-6703-408f-be2d-48c6b82ad714"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 ▶ Train SmoothL1: 2.1559\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 2.1402\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 02 ▶ Train SmoothL1: 1.2872\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 1.9945\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 03 ▶ Train SmoothL1: 0.9879\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 0.9034\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 04 ▶ Train SmoothL1: 0.8334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 1.1317\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 05 ▶ Train SmoothL1: 0.7943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 1.3011\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 06 ▶ Train SmoothL1: 0.6681\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 1.4668\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 07 ▶ Train SmoothL1: 0.5610\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 0.9393\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 08 ▶ Train SmoothL1: 0.3853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 2.0100\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 09 ▶ Train SmoothL1: 0.3270\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 1.5663\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 ▶ Train SmoothL1: 0.2831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 1.2631\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# ─── Cell 6: TRAIN & VALIDATE (PRINT TRAIN/VAL SmoothL1) ──────────────────────\n",
        "import warnings\n",
        "# suppress the per-iteration AMP FutureWarning that was cluttering the console\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=FutureWarning,\n",
        "    module=\"torch\\\\.cuda\\\\.amp\"\n",
        ")\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    # — Training —\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    # one clean tqdm line\n",
        "    train_bar = tqdm(\n",
        "        train_loader,\n",
        "        desc=f\"Epoch {epoch:02d} ▶ Train\",\n",
        "        leave=False,\n",
        "        dynamic_ncols=True\n",
        "    )\n",
        "    for imgs, weather, masks in train_bar:\n",
        "        imgs, weather, masks = imgs.to(device), weather.to(device), masks.to(device)\n",
        "        opt.zero_grad()\n",
        "        # use the new autocast API to avoid the warning\n",
        "        with torch.amp.autocast(device_type=\"cuda\"):\n",
        "            preds = model(imgs, weather)\n",
        "            loss  = loss_fn(preds, masks)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item() * imgs.size(0)\n",
        "        train_bar.set_postfix(smoothl1=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_train = train_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch:02d} ▶ Train SmoothL1: {avg_train:.4f}\")\n",
        "\n",
        "    # — Validation —\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_bar  = tqdm(\n",
        "        val_loader,\n",
        "        desc=f\"Epoch {epoch:02d} ▶ Val  \",\n",
        "        leave=False,\n",
        "        dynamic_ncols=True\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        for imgs, weather, masks in val_bar:\n",
        "            imgs, weather, masks = imgs.to(device), weather.to(device), masks.to(device)\n",
        "            with torch.amp.autocast(device_type=\"cuda\"):\n",
        "                preds = model(imgs, weather)\n",
        "                loss  = loss_fn(preds, masks)\n",
        "\n",
        "            val_loss += loss.item() * imgs.size(0)\n",
        "            val_bar.set_postfix(smoothl1=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_val = val_loss / len(val_loader.dataset)\n",
        "    print(f\"           Val   SmoothL1: {avg_val:.4f}\\n\")\n",
        "\n",
        "    # — Update LR scheduler on validation metric —\n",
        "    scheduler.step(avg_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0vTnm6FDE97"
      },
      "outputs": [],
      "source": [
        "# ─── Cell 3: DATASET WITH AGGRESSIVE AUGMENTATION ───────────────────────────────\n",
        "class LSTDataset(Dataset):\n",
        "    def __init__(self, df, patches_dir, weather_cols):\n",
        "        self.df           = df.reset_index(drop=True)\n",
        "        self.patches_dir  = patches_dir\n",
        "        self.weather_cols = weather_cols\n",
        "        self.transform    = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((224,224)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.RandomRotation(20),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row  = self.df.loc[idx]\n",
        "        arr  = imread(os.path.join(self.patches_dir, row[\"filename\"])).astype(np.float32)\n",
        "\n",
        "        # Image input\n",
        "        img_np = arr[[1,2,3]].transpose(1,2,0).astype(np.uint8)\n",
        "        img    = self.transform(img_np)\n",
        "\n",
        "        # Target LST\n",
        "        lst    = torch.tensor(arr[0], dtype=torch.float32).unsqueeze(0)\n",
        "        lst    = F.interpolate(lst.unsqueeze(0), size=(224,224),\n",
        "                               mode='bilinear', align_corners=False\n",
        "                              ).squeeze(0)\n",
        "\n",
        "        # Weather vector\n",
        "        weather = torch.tensor(\n",
        "            row[self.weather_cols].values.astype(np.float32)\n",
        "        )\n",
        "        return img, weather, lst\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JPk-D60Gu14"
      },
      "outputs": [],
      "source": [
        "# define which meteorological columns to pull\n",
        "weather_cols = [\n",
        "    \"air_temp_C\",\n",
        "    \"dew_point_C\",\n",
        "    \"relative_humidity_percent\",\n",
        "    \"wind_speed_m_s\",\n",
        "    \"precipitation_in\",\n",
        "]\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/PatchedOutput/tiff_with_meteo.csv\")\n",
        "for col in weather_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "df = df.dropna(subset=weather_cols + [\"filename\"]).reset_index(drop=True)\n",
        "\n",
        "patches_dir = \"/content/drive/MyDrive/PatchedOutput_Cleaned\"\n",
        "dataset     = LSTDataset(df, patches_dir, weather_cols)\n",
        "train_sz    = int(0.8 * len(dataset))\n",
        "val_sz      = len(dataset) - train_sz\n",
        "train_ds, val_ds = random_split(dataset, [train_sz, val_sz])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  num_workers=0, pin_memory=False)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, num_workers=0, pin_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSDpKnKHDHKP"
      },
      "outputs": [],
      "source": [
        "# ─── Cell 4: ViT-UNet WITH SPATIAL DROPOUT ─────────────────────────────────────\n",
        "class ViTUNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, weather_dim=5, base_channels=64,\n",
        "                 num_heads=8, trans_layers=2, trans_dim=512):\n",
        "        super().__init__()\n",
        "        def conv_block(in_ch, out_ch, p_drop=0.2):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "                nn.BatchNorm2d(out_ch),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout2d(p_drop),\n",
        "                nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "                nn.BatchNorm2d(out_ch),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "        # Encoder with dropout\n",
        "        self.conv1 = conv_block(in_channels,    base_channels,    p_drop=0.2)\n",
        "        self.conv2 = conv_block(base_channels,  base_channels*2,  p_drop=0.2)\n",
        "        self.conv3 = conv_block(base_channels*2,base_channels*4,  p_drop=0.2)\n",
        "        self.conv4 = conv_block(base_channels*4,base_channels*8,  p_drop=0.2)\n",
        "        self.conv5 = conv_block(base_channels*8,base_channels*8,  p_drop=0.2)\n",
        "        self.pool  = nn.MaxPool2d(2)\n",
        "\n",
        "        # Weather projection & transformer (unchanged)…\n",
        "        self.weather_proj   = nn.Linear(weather_dim, trans_dim)\n",
        "        self.bottleneck_proj = nn.Conv2d(base_channels*8, trans_dim, 1)\n",
        "        self.pos_embed       = nn.Parameter(torch.zeros(1, 14*14, trans_dim))\n",
        "        self.weather_token   = nn.Parameter(torch.zeros(1,1,trans_dim))\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=trans_dim, nhead=num_heads,\n",
        "            dim_feedforward=trans_dim*4, dropout=0.1, batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=trans_layers)\n",
        "\n",
        "        # Decoder upsample & convs (unchanged)…\n",
        "        self.up4 = nn.ConvTranspose2d(trans_dim,     base_channels*8, 2,2)\n",
        "        self.up3 = nn.ConvTranspose2d(base_channels*8, base_channels*4, 2,2)\n",
        "        self.up2 = nn.ConvTranspose2d(base_channels*4, base_channels*2, 2,2)\n",
        "        self.up1 = nn.ConvTranspose2d(base_channels*2, base_channels,   2,2)\n",
        "        self.dec4 = conv_block(base_channels*8 + base_channels*8, base_channels*8, p_drop=0.2)\n",
        "        self.dec3 = conv_block(base_channels*4 + base_channels*4, base_channels*4, p_drop=0.2)\n",
        "        self.dec2 = conv_block(base_channels*2 + base_channels*2, base_channels*2, p_drop=0.2)\n",
        "        self.dec1 = conv_block(base_channels   + base_channels,   base_channels,   p_drop=0.2)\n",
        "        self.final_conv = nn.Conv2d(base_channels, 1, 1)\n",
        "\n",
        "    def forward(self, x, weather):\n",
        "        # same forward as before…\n",
        "        B,C,H,W = x.shape\n",
        "        e1 = self.conv1(x)\n",
        "        e2 = self.conv2(self.pool(e1))\n",
        "        e3 = self.conv3(self.pool(e2))\n",
        "        e4 = self.conv4(self.pool(e3))\n",
        "        e5 = self.conv5(self.pool(e4))\n",
        "\n",
        "        bt      = self.bottleneck_proj(e5)\n",
        "        N       = bt.shape[2]*bt.shape[3]\n",
        "        bt_flat = bt.view(B, bt.shape[1], N).permute(0,2,1)\n",
        "        bt_pos  = bt_flat + self.pos_embed[:, :N, :]\n",
        "        w_tok   = self.weather_proj(weather).unsqueeze(1) + self.weather_token\n",
        "        trans   = torch.cat([bt_pos, w_tok], dim=1)\n",
        "        out_t   = self.transformer(trans)\n",
        "        spat    = out_t[:, :-1, :]\n",
        "        fs      = int(math.sqrt(spat.size(1)))\n",
        "        f_ts    = spat.permute(0,2,1).view(B, bt.shape[1], fs, fs)\n",
        "\n",
        "        d4 = self.dec4(torch.cat([self.up4(f_ts), e4], dim=1))\n",
        "        d3 = self.dec3(torch.cat([self.up3(d4),  e3], dim=1))\n",
        "        d2 = self.dec2(torch.cat([self.up2(d3),  e2], dim=1))\n",
        "        d1 = self.dec1(torch.cat([self.up1(d2),  e1], dim=1))\n",
        "        return self.final_conv(d1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjB-l0ygG5eI",
        "outputId": "e2dd52d1-e61b-425b-8e18-fc3984c7bc88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model, SmoothL1Loss, optimizer & scheduler ready\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "<ipython-input-40-3411cbb376b4>:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# ─── Cell 5: INITIALIZE MODEL, SmoothL1Loss, OPTIMIZER & LR SCHEDULER ─────────\n",
        "device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model     = ViTUNet(in_channels=3, weather_dim=len(weather_cols)).to(device)\n",
        "\n",
        "# Use SmoothL1 (Huber) loss instead of MSE\n",
        "loss_fn = nn.SmoothL1Loss()\n",
        "\n",
        "# Optimizer: only on parameters that require grad\n",
        "opt = torch.optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-2\n",
        ")\n",
        "\n",
        "# Reduce LR on plateau of validation loss\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    opt,\n",
        "    mode='min',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "scaler = GradScaler()\n",
        "\n",
        "print(\"✅ Model, SmoothL1Loss, optimizer & scheduler ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RggY7W4xDt6H",
        "outputId": "f8554f93-2670-4ea4-a736-61b76aced203"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 ▶ Train SmoothL1: 2.9314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 2.2961\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 02 ▶ Train SmoothL1: 2.5191\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 4.2387\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 03 ▶ Train SmoothL1: 2.5855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 2.3298\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 04 ▶ Train SmoothL1: 2.3638\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 2.3189\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 05 ▶ Train SmoothL1: 2.2857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 2.2814\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 06 ▶ Train SmoothL1: 2.2344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 2.3143\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 07 ▶ Train SmoothL1: 2.1900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 2.2961\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 08 ▶ Train SmoothL1: 2.2054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 2.1888\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 09 ▶ Train SmoothL1: 2.1270\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 2.3965\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 ▶ Train SmoothL1: 2.1667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Val   SmoothL1: 2.2493\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# ─── Cell 6: TRAIN & VALIDATE WITH EARLY STOPPING ──────────────────────────────\n",
        "import warnings\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=FutureWarning,\n",
        "    module=\"torch\\\\.cuda\\\\.amp\"\n",
        ")\n",
        "\n",
        "patience           = 5\n",
        "best_val           = float('inf')\n",
        "epochs_no_improve  = 0\n",
        "num_epochs         = 10\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    # —— Training ——\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_bar  = tqdm(train_loader, desc=f\"Epoch {epoch:02d} ▶ Train\", leave=False)\n",
        "    for imgs, weather, masks in train_bar:\n",
        "        imgs, weather, masks = imgs.to(device), weather.to(device), masks.to(device)\n",
        "        opt.zero_grad()\n",
        "        with torch.amp.autocast(device_type=\"cuda\"):\n",
        "            preds = model(imgs, weather)\n",
        "            loss  = loss_fn(preds, masks)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item() * imgs.size(0)\n",
        "        train_bar.set_postfix(smoothl1=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_train = train_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch:02d} ▶ Train SmoothL1: {avg_train:.4f}\")\n",
        "\n",
        "    # —— Validation ——\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_bar  = tqdm(val_loader, desc=f\"Epoch {epoch:02d} ▶ Val  \", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for imgs, weather, masks in val_bar:\n",
        "            imgs, weather, masks = imgs.to(device), weather.to(device), masks.to(device)\n",
        "            with torch.amp.autocast(device_type=\"cuda\"):\n",
        "                preds = model(imgs, weather)\n",
        "                loss  = loss_fn(preds, masks)\n",
        "\n",
        "            val_loss += loss.item() * imgs.size(0)\n",
        "            val_bar.set_postfix(smoothl1=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_val = val_loss / len(val_loader.dataset)\n",
        "    print(f\"           Val   SmoothL1: {avg_val:.4f}\\n\")\n",
        "\n",
        "    # Scheduler step and early stopping\n",
        "    scheduler.step(avg_val)\n",
        "    if avg_val < best_val:\n",
        "        best_val          = avg_val\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"↳ Early stopping at epoch {epoch}\")\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfqbJRpsIbfq"
      },
      "source": [
      
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 ▶ Consolidated imports\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import timm\n",
        "from torchvision import transforms, models\n",
        "\n",
        "from tifffile import imread"
      ],
      "metadata": {
        "id": "nJNImWiQxmm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P787weC3Ig9o"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "\n",
        "def conv_block(in_ch, out_ch):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_ch,  out_ch, 3, padding=1),\n",
        "        nn.BatchNorm2d(out_ch),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "        nn.BatchNorm2d(out_ch),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "class ViTUNet(nn.Module):\n",
        "    def __init__(self, weather_dim=5, trans_dim=512, num_heads=8, trans_layers=2):\n",
        "        super().__init__()\n",
        "        # Encoder: ResNet34 backbone\n",
        "        self.backbone = timm.create_model(\n",
        "            'resnet34', pretrained=True, features_only=True,\n",
        "            out_indices=[0,1,2,3,4], in_chans=3\n",
        "        )\n",
        "        feats = self.backbone.feature_info.channels()  # [64, 64, 128, 256, 512]\n",
        "\n",
        "        # Weather token & pos-embed\n",
        "        self.weather_proj   = nn.Linear(weather_dim, trans_dim)\n",
        "        self.weather_token  = nn.Parameter(torch.zeros(1, 1, trans_dim))\n",
        "        self.pos_embed      = nn.Parameter(torch.zeros(1, 14*14, trans_dim))\n",
        "\n",
        "        # Bottleneck projection & transformer\n",
        "        self.bottleneck_proj = nn.Conv2d(feats[-1], trans_dim, 1)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=trans_dim, nhead=num_heads,\n",
        "            dim_feedforward=trans_dim*4, dropout=0.1, batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=trans_layers)\n",
        "\n",
        "        # Decoder upsample & convs\n",
        "        self.up4 = nn.ConvTranspose2d(trans_dim,   feats[3], 2, 2)\n",
        "        self.dec4 = conv_block(feats[3]*2, feats[3])\n",
        "        self.up3 = nn.ConvTranspose2d(feats[3],    feats[2], 2, 2)\n",
        "        self.dec3 = conv_block(feats[2]*2, feats[2])\n",
        "        self.up2 = nn.ConvTranspose2d(feats[2],    feats[1], 2, 2)\n",
        "        self.dec2 = conv_block(feats[1]*2, feats[1])\n",
        "        self.up1 = nn.ConvTranspose2d(feats[1],    feats[0], 2, 2)\n",
        "        self.dec1 = conv_block(feats[0]*2, feats[0])\n",
        "        self.final_conv = nn.Conv2d(feats[0], 1, 1)\n",
        "\n",
        "    def forward(self, x, weather):\n",
        "        # 1) remember input size\n",
        "        orig_h, orig_w = x.shape[2], x.shape[3]\n",
        "\n",
        "        # 2) Encoder\n",
        "        e1, e2, e3, e4, e5 = self.backbone(x)   # 224→112→56→28→14\n",
        "\n",
        "        # 3) Bottleneck + Transformer prep\n",
        "        bt = self.bottleneck_proj(e5)           # [B, C, 14, 14]\n",
        "        B, C, H, W = bt.shape\n",
        "        N = H * W\n",
        "        feat = bt.view(B, C, N).permute(0, 2, 1)      # [B, N, C]\n",
        "        feat = feat + self.pos_embed[:, :N, :]       # add positional\n",
        "        w_tok = self.weather_proj(weather).unsqueeze(1) + self.weather_token\n",
        "        trans = torch.cat([feat, w_tok], dim=1)       # [B, N+1, C]\n",
        "        out_t = self.transformer(trans)               # [B, N+1, C]\n",
        "\n",
        "        # 4) reshape back to 2D feature map\n",
        "        feat = out_t[:, :-1, :]                       # drop weather token → [B, N, C]\n",
        "        fs = int(math.sqrt(feat.size(1)))             # should be 14\n",
        "        f_ts = feat.permute(0, 2, 1).view(B, C, fs, fs)  # [B, C, 14, 14]\n",
        "\n",
        "        # 5) Decoder\n",
        "        d4 = self.dec4(torch.cat([self.up4(f_ts), e4], dim=1))\n",
        "        d3 = self.dec3(torch.cat([self.up3(d4),  e3], dim=1))\n",
        "        d2 = self.dec2(torch.cat([self.up2(d3),  e2], dim=1))\n",
        "        d1 = self.dec1(torch.cat([self.up1(d2),  e1], dim=1))\n",
        "\n",
        "        # 6) Final conv + upsample back to 224×224\n",
        "        out = self.final_conv(d1)\n",
        "        out = F.interpolate(\n",
        "            out,\n",
        "            size=(orig_h, orig_w),\n",
        "            mode='bilinear',\n",
        "            align_corners=False\n",
        "        )\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 3: DATASET WITH AGGRESSIVE AUGMENTATION ───────────────────────────────\n",
        "class LSTDataset(Dataset):\n",
        "    def __init__(self, df, patches_dir, weather_cols):\n",
        "        self.df           = df.reset_index(drop=True)\n",
        "        self.patches_dir  = patches_dir\n",
        "        self.weather_cols = weather_cols\n",
        "        self.transform    = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((224,224)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.RandomRotation(20),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row  = self.df.loc[idx]\n",
        "        arr  = imread(os.path.join(self.patches_dir, row[\"filename\"])).astype(np.float32)\n",
        "\n",
        "        # Image input\n",
        "        img_np = arr[[1,2,3]].transpose(1,2,0).astype(np.uint8)\n",
        "        img    = self.transform(img_np)\n",
        "\n",
        "        # Target LST\n",
        "        lst    = torch.tensor(arr[0], dtype=torch.float32).unsqueeze(0)\n",
        "        lst    = F.interpolate(lst.unsqueeze(0), size=(224,224),\n",
        "                               mode='bilinear', align_corners=False\n",
        "                              ).squeeze(0)\n",
        "\n",
        "        # Weather vector\n",
        "        weather = torch.tensor(\n",
        "            row[self.weather_cols].values.astype(np.float32)\n",
        "        )\n",
        "        return img, weather, lst\n"
      ],
      "metadata": {
        "id": "J368wrLcuRrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qepndFZyx8C-",
        "outputId": "ef486aad-beae-402e-a5b1-7ea2f979a432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define which meteorological columns to pull\n",
        "weather_cols = [\n",
        "    \"air_temp_C\",\n",
        "    \"dew_point_C\",\n",
        "    \"relative_humidity_percent\",\n",
        "    \"wind_speed_m_s\",\n",
        "    \"precipitation_in\",\n",
        "]\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/PatchedOutput/tiff_with_meteo.csv\")\n",
        "for col in weather_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "df = df.dropna(subset=weather_cols + [\"filename\"]).reset_index(drop=True)\n",
        "\n",
        "patches_dir = \"/content/drive/MyDrive/PatchedOutput_Cleaned\"\n",
        "dataset     = LSTDataset(df, patches_dir, weather_cols)\n",
        "train_sz    = int(0.8 * len(dataset))\n",
        "val_sz      = len(dataset) - train_sz\n",
        "train_ds, val_ds = random_split(dataset, [train_sz, val_sz])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  num_workers=0, pin_memory=False)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, num_workers=0, pin_memory=False)"
      ],
      "metadata": {
        "id": "jiSka8CwtADy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 0: Install TIFF LZW support ─────────────────────────────────────────\n",
        "!pip install imagecodecs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO-2sa_hwOaZ",
        "outputId": "9443d782-9171-4f36-fba2-01dfc0be2e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imagecodecs\n",
            "  Downloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imagecodecs) (2.0.2)\n",
            "Downloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imagecodecs\n",
            "Successfully installed imagecodecs-2025.3.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 0: install the SSIM library ─────────────────────────────────────────\n",
        "!pip install piq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Wvuq0mxu6gc",
        "outputId": "48462555-6561-45e2-d708-dbfb9a87b13e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting piq\n",
            "  Downloading piq-0.8.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from piq) (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.10.0->piq) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.10.0->piq) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.10.0->piq) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision>=0.10.0->piq) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision>=0.10.0->piq) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision>=0.10.0->piq) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision>=0.10.0->piq) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision>=0.10.0->piq) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision>=0.10.0->piq)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision>=0.10.0->piq)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision>=0.10.0->piq)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision>=0.10.0->piq)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision>=0.10.0->piq)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision>=0.10.0->piq)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision>=0.10.0->piq)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision>=0.10.0->piq)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision>=0.10.0->piq)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision>=0.10.0->piq) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision>=0.10.0->piq) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision>=0.10.0->piq) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision>=0.10.0->piq)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision>=0.10.0->piq) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision>=0.10.0->piq) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision>=0.10.0->piq) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision>=0.10.0->piq) (3.0.2)\n",
            "Downloading piq-0.8.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, piq\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 piq-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQf4RV5PIm2y",
        "outputId": "4fd02170-f4bc-4d09-c57b-49cee5039ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model, SmoothL1+SSIM, OneCycleLR ready\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-70747d7d5168>:31: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# ─── Cell 5: INITIALIZE MODEL, SmoothL1+SSIM LOSS & One-Cycle LR ─────────────\n",
        "import torch\n",
        "from torch.cuda.amp import GradScaler\n",
        "from piq import ssim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model  = ViTUNet(weather_dim=len(weather_cols)).to(device)\n",
        "\n",
        "# Losses\n",
        "loss_fn = nn.SmoothL1Loss()\n",
        "\n",
        "# Optimizer\n",
        "opt = torch.optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=1e-3, weight_decay=1e-2\n",
        ")\n",
        "\n",
        "# OneCycleLR scheduler\n",
        "num_epochs     = 10\n",
        "steps_per_epoch = len(train_loader)\n",
        "scheduler      = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    opt,\n",
        "    max_lr=1e-3,\n",
        "    total_steps=steps_per_epoch * num_epochs,\n",
        "    pct_start=0.3,\n",
        "    anneal_strategy='cos',\n",
        "    div_factor=25.0,\n",
        "    final_div_factor=1e4\n",
        ")\n",
        "\n",
        "scaler = GradScaler()\n",
        "print(\"✅ Model, SmoothL1+SSIM, OneCycleLR ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43zP2iR-JMoq"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z68DBfVTKQYn"
      },
      "outputs": [],
      "source": [
        "# ─── Cell 4: ViT-UNet WITH DEEP SUPERVISION ────────────────────────────────────\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ViTUNetDS(nn.Module):\n",
        "    def __init__(self, in_channels=3, weather_dim=5, base_channels=64,\n",
        "                 num_heads=8, trans_layers=2, trans_dim=512):\n",
        "        super().__init__()\n",
        "        def conv_block(in_ch, out_ch):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_ch,  out_ch, 3, padding=1),\n",
        "                nn.BatchNorm2d(out_ch),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "                nn.BatchNorm2d(out_ch),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "\n",
        "        # Encoder\n",
        "        self.conv1 = conv_block(in_channels,    base_channels)\n",
        "        self.conv2 = conv_block(base_channels,  base_channels*2)\n",
        "        self.conv3 = conv_block(base_channels*2,base_channels*4)\n",
        "        self.conv4 = conv_block(base_channels*4,base_channels*8)\n",
        "        self.conv5 = conv_block(base_channels*8,base_channels*8)\n",
        "        self.pool  = nn.MaxPool2d(2)\n",
        "\n",
        "        # Weather + Transformer\n",
        "        self.weather_proj    = nn.Linear(weather_dim, trans_dim)\n",
        "        self.weather_token   = nn.Parameter(torch.zeros(1,1,trans_dim))\n",
        "        self.pos_embed       = nn.Parameter(torch.zeros(1,14*14,trans_dim))\n",
        "        self.bottleneck_proj = nn.Conv2d(base_channels*8, trans_dim, 1)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=trans_dim, nhead=num_heads,\n",
        "            dim_feedforward=trans_dim*4, dropout=0.1, batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=trans_layers)\n",
        "\n",
        "        # Decoder\n",
        "        self.up4 = nn.ConvTranspose2d(trans_dim,     base_channels*8, 2,2)\n",
        "        self.dec4 = conv_block(base_channels*8*2,   base_channels*8)\n",
        "        self.up3 = nn.ConvTranspose2d(base_channels*8, base_channels*4, 2,2)\n",
        "        self.dec3 = conv_block(base_channels*4*2,   base_channels*4)\n",
        "        self.up2 = nn.ConvTranspose2d(base_channels*4, base_channels*2, 2,2)\n",
        "        self.dec2 = conv_block(base_channels*2*2,   base_channels*2)\n",
        "        self.up1 = nn.ConvTranspose2d(base_channels*2, base_channels,   2,2)\n",
        "        self.dec1 = conv_block(base_channels*2,     base_channels)\n",
        "        self.final_conv = nn.Conv2d(base_channels, 1, 1)\n",
        "\n",
        "        # Deep-supervision heads\n",
        "        self.aux_conv3 = nn.Conv2d(base_channels*4, 1, 1)  # from d3\n",
        "        self.aux_conv2 = nn.Conv2d(base_channels*2, 1, 1)  # from d2\n",
        "\n",
        "    def forward(self, x, weather):\n",
        "        e1 = self.conv1(x)\n",
        "        e2 = self.conv2(self.pool(e1))\n",
        "        e3 = self.conv3(self.pool(e2))\n",
        "        e4 = self.conv4(self.pool(e3))\n",
        "        e5 = self.conv5(self.pool(e4))\n",
        "\n",
        "        bt = self.bottleneck_proj(e5)\n",
        "        B,C,H,W = bt.shape\n",
        "        N = H*W\n",
        "        bt_flat = bt.view(B,C,N).permute(0,2,1)\n",
        "        bt_pos  = bt_flat + self.pos_embed[:, :N, :]\n",
        "        w_tok   = self.weather_proj(weather).unsqueeze(1) + self.weather_token\n",
        "        trans   = torch.cat([bt_pos, w_tok], dim=1)\n",
        "        out_t   = self.transformer(trans)\n",
        "        spat    = out_t[:, :-1, :]\n",
        "        fs      = int(math.sqrt(spat.size(1)))\n",
        "        f_ts    = spat.permute(0,2,1).view(B, C, fs, fs)\n",
        "\n",
        "        d4 = self.dec4(torch.cat([self.up4(f_ts), e4], dim=1))\n",
        "        d3 = self.dec3(torch.cat([self.up3(d4),  e3], dim=1))\n",
        "        d2 = self.dec2(torch.cat([self.up2(d3),  e2], dim=1))\n",
        "        d1 = self.dec1(torch.cat([self.up1(d2),  e1], dim=1))\n",
        "\n",
        "        main_out = self.final_conv(d1)\n",
        "        aux3     = F.interpolate(self.aux_conv3(d3), size=(224,224),\n",
        "                                 mode='bilinear', align_corners=False)\n",
        "        aux2     = F.interpolate(self.aux_conv2(d2), size=(224,224),\n",
        "                                 mode='bilinear', align_corners=False)\n",
        "        return main_out, aux3, aux2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BNijZjOKUJu",
        "outputId": "edbce1b1-03d6-4fdc-8718-6f8a2f06c928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DS Model, optimizer & OneCycleLR ready\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-09c77addf136>:29: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# ─── Cell 5: INIT MODEL, LOSS, OPTIMIZER & ONE-CYCLE LR ───────────────────────\n",
        "from torch.cuda.amp import GradScaler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model  = ViTUNetDS(in_channels=3, weather_dim=len(weather_cols)).to(device)\n",
        "\n",
        "# Loss\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Optimizer\n",
        "opt = torch.optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=1e-4, weight_decay=1e-2\n",
        ")\n",
        "\n",
        "# One-Cycle LR scheduler\n",
        "num_epochs      = 10\n",
        "steps_per_epoch = len(train_loader)\n",
        "scheduler       = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    opt,\n",
        "    max_lr=1e-3,\n",
        "    total_steps=steps_per_epoch * num_epochs,\n",
        "    pct_start=0.3,\n",
        "    anneal_strategy='cos',\n",
        "    div_factor=25.0,\n",
        "    final_div_factor=1e4\n",
        ")\n",
        "\n",
        "scaler = GradScaler()\n",
        "print(\"✅ DS Model, optimizer & OneCycleLR ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWVC3HIEKYDO",
        "outputId": "fb55fe73-321d-4604-89b5-16a80691e95d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 ▶ Train Loss: 122.4519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Val Loss:   112.8348\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02 ▶ Train Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Val Loss:   nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03 ▶ Train Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Val Loss:   nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04 ▶ Train Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Val Loss:   nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05 ▶ Train Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Val Loss:   nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06 ▶ Train Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Val Loss:   nan\n",
            "\n",
            "↳ Early stopping at epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# ─── Cell 6: TRAIN/VAL with MixUp + Deep Supervision (fixed warnings & one‐line tqdm) ───\n",
        "import numpy as np\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "from torch.cuda.amp import GradScaler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# suppress all FutureWarnings (including the autocast deprecation)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "def mixup_data(x, y, w, alpha=0.4):\n",
        "    lam = np.random.beta(alpha, alpha) if alpha>0 else 1.0\n",
        "    idx = torch.randperm(x.size(0), device=x.device)\n",
        "    return lam*x + (1-lam)*x[idx], lam*w + (1-lam)*w[idx], lam*y + (1-lam)*y[idx]\n",
        "\n",
        "patience, best_val, no_imp = 5, float('inf'), 0\n",
        "scaler = GradScaler()\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    # — Training —\n",
        "    model.train()\n",
        "    t_loss = 0\n",
        "    train_bar = tqdm(\n",
        "        train_loader,\n",
        "        desc=f\"Epoch {epoch:02d} ▶ Train\",\n",
        "        leave=False,\n",
        "        dynamic_ncols=True\n",
        "    )\n",
        "    for imgs, weather, masks in train_bar:\n",
        "        imgs, weather, masks = imgs.to(device), weather.to(device), masks.to(device)\n",
        "        xim, wim, yim        = mixup_data(imgs, masks, weather, alpha=0.4)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        # use the new autocast API to avoid deprecation warnings\n",
        "        with torch.amp.autocast(\"cuda\"):\n",
        "            pm, pa3, pa2 = model(xim, wim)\n",
        "            l0 = loss_fn(pm, yim)\n",
        "            l3 = loss_fn(pa3, yim)\n",
        "            l2 = loss_fn(pa2, yim)\n",
        "            loss = l0 + 0.5*(l3 + l2)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "        scheduler.step()\n",
        "\n",
        "        t_loss += loss.item() * imgs.size(0)\n",
        "        train_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_t = t_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch:02d} ▶ Train Loss: {avg_t:.4f}\")\n",
        "\n",
        "    # — Validation —\n",
        "    model.eval()\n",
        "    v_loss = 0\n",
        "    val_bar = tqdm(\n",
        "        val_loader,\n",
        "        desc=f\"Epoch {epoch:02d} ▶ Val  \",\n",
        "        leave=False,\n",
        "        dynamic_ncols=True\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        for imgs, weather, masks in val_bar:\n",
        "            imgs, weather, masks = imgs.to(device), weather.to(device), masks.to(device)\n",
        "            with torch.amp.autocast(\"cuda\"):\n",
        "                pm, pa3, pa2 = model(imgs, weather)\n",
        "                l0 = loss_fn(pm, masks)\n",
        "                l3 = loss_fn(pa3, masks)\n",
        "                l2 = loss_fn(pa2, masks)\n",
        "                loss = l0 + 0.5*(l3 + l2)\n",
        "\n",
        "            v_loss += loss.item() * imgs.size(0)\n",
        "            val_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_v = v_loss / len(val_loader.dataset)\n",
        "    print(f\"           Val Loss:   {avg_v:.4f}\\n\")\n",
        "\n",
        "    # — Early stopping —\n",
        "    if avg_v < best_val:\n",
        "        best_val, no_imp = avg_v, 0\n",
        "        torch.save(model.state_dict(), 'best_ds.pth')\n",
        "    else:\n",
        "        no_imp += 1\n",
        "        if no_imp >= patience:\n",
        "            print(f\"↳ Early stopping at epoch {epoch}\")\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 0: install Optuna ─────────────────────────────────────────────────\n",
        "!pip install optuna\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkc6rUAe6hJz",
        "outputId": "4d109115-dbca-47a0-af57-550d30e0599d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "PNHRVcHaKciS",
        "outputId": "7d45ab6c-a5db-4128-c914-6b836dd6da5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-26 13:35:53,693] A new study created in memory with name: no-name-63810d19-d221-4a8f-9f54-7aa424ce2cef\n",
            "[W 2025-04-26 13:35:54,203] Trial 0 failed with parameters: {'lr': 2.5672848672791938e-05, 'wd': 1.0595219092334e-06, 'mixup_alpha': 0.16335933798614355, 'aux_weight': 0.18221419820502227} because of the following error: ValueError('not enough values to unpack (expected 4, got 3)').\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"<ipython-input-24-f4aceaff4921>\", line 20, in objective\n",
            "    xim, wim, yim, _     = mixup_data(imgs, masks, weather, alpha)\n",
            "    ^^^^^^^^^^^^^^^^\n",
            "ValueError: not enough values to unpack (expected 4, got 3)\n",
            "[W 2025-04-26 13:35:54,215] Trial 0 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 4, got 3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f4aceaff4921>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best params:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best val:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-f4aceaff4921>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mxim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mmixup_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
          ]
        }
      ],
      "source": [
        "# ─── Cell 7: HYPERPARAMETER SWEEP (Optuna) ─────────────────────────────────────\n",
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    lr    = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
        "    wd    = trial.suggest_loguniform(\"wd\", 1e-6, 1e-2)\n",
        "    alpha = trial.suggest_uniform(\"mixup_alpha\", 0.0, 1.0)\n",
        "    aw    = trial.suggest_uniform(\"aux_weight\", 0.0, 1.0)\n",
        "\n",
        "    model = ViTUNetDS().to(device)\n",
        "    opt   = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"min\", factor=0.5, patience=2)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    scaler  = GradScaler()\n",
        "\n",
        "    for _ in range(3):\n",
        "        model.train()\n",
        "        for imgs, weather, masks in train_loader:\n",
        "            imgs, weather, masks = imgs.to(device), weather.to(device), masks.to(device)\n",
        "            xim, wim, yim, _     = mixup_data(imgs, masks, weather, alpha)\n",
        "            opt.zero_grad()\n",
        "            with autocast(device_type=\"cuda\"):\n",
        "                pm, pa3, pa2 = model(xim, wim)\n",
        "                l0 = loss_fn(pm, yim)\n",
        "                l3 = loss_fn(pa3, yim)\n",
        "                l2 = loss_fn(pa2, yim)\n",
        "                loss = l0 + aw*(l3 + l2)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "        # val\n",
        "        model.eval()\n",
        "        v_loss = 0\n",
        "        with torch.no_grad(), autocast(device_type=\"cuda\"):\n",
        "            for imgs, weather, masks in val_loader:\n",
        "                imgs, weather, masks = imgs.to(device), weather.to(device), masks.to(device)\n",
        "                pm, pa3, pa2 = model(imgs, weather)\n",
        "                l0 = loss_fn(pm, masks)\n",
        "                l3 = loss_fn(pa3, masks)\n",
        "                l2 = loss_fn(pa2, masks)\n",
        "                v_loss += (l0 + aw*(l3 + l2)).item() * imgs.size(0)\n",
        "        avg_v = v_loss / len(val_loader.dataset)\n",
        "        sched.step(avg_v)\n",
        "\n",
        "    return avg_v\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "print(\"Best params:\", study.best_params)\n",
        "print(\"Best val:\", study.best_value)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
