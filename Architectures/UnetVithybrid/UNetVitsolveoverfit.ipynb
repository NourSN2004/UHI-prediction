{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNoklLm5ES1F"
      },
      "outputs": [],
      "source": [
        "# In your setup cell (Cell 1), after mounting drive:\n",
        "!pip install timm torchvision tifffile imagecodecs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Mount Drive & install\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install timm torchvision tifffile\n"
      ],
      "metadata": {
        "id": "bHY3iNhcEbt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 ▶ Consolidated imports\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import timm\n",
        "from torchvision import transforms, models\n",
        "\n",
        "from tifffile import imread"
      ],
      "metadata": {
        "id": "nt5wn6-1EdGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 3: DATASET WITH AGGRESSIVE AUGMENTATION ───────────────────────────────\n",
        "class LSTDataset(Dataset):\n",
        "    def __init__(self, df, patches_dir, weather_cols):\n",
        "        self.df           = df.reset_index(drop=True)\n",
        "        self.patches_dir  = patches_dir\n",
        "        self.weather_cols = weather_cols\n",
        "        self.transform    = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((224,224)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.RandomRotation(20),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row  = self.df.loc[idx]\n",
        "        arr  = imread(os.path.join(self.patches_dir, row[\"filename\"])).astype(np.float32)\n",
        "\n",
        "        # Image input\n",
        "        img_np = arr[[1,2,3]].transpose(1,2,0).astype(np.uint8)\n",
        "        img    = self.transform(img_np)\n",
        "\n",
        "        # Target LST\n",
        "        lst    = torch.tensor(arr[0], dtype=torch.float32).unsqueeze(0)\n",
        "        lst    = F.interpolate(lst.unsqueeze(0), size=(224,224),\n",
        "                               mode='bilinear', align_corners=False\n",
        "                              ).squeeze(0)\n",
        "\n",
        "        # Weather vector\n",
        "        weather = torch.tensor(\n",
        "            row[self.weather_cols].values.astype(np.float32)\n",
        "        )\n",
        "        return img, weather, lst\n"
      ],
      "metadata": {
        "id": "p2FUf7t-EiOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 4: ViT-UNet WITH SPATIAL DROPOUT ─────────────────────────────────────\n",
        "class ViTUNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, weather_dim=5, base_channels=64,\n",
        "                 num_heads=8, trans_layers=2, trans_dim=512):\n",
        "        super().__init__()\n",
        "        def conv_block(in_ch, out_ch, p_drop=0.2):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "                nn.BatchNorm2d(out_ch),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout2d(p_drop),\n",
        "                nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "                nn.BatchNorm2d(out_ch),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "        # Encoder with dropout\n",
        "        self.conv1 = conv_block(in_channels,    base_channels,    p_drop=0.2)\n",
        "        self.conv2 = conv_block(base_channels,  base_channels*2,  p_drop=0.2)\n",
        "        self.conv3 = conv_block(base_channels*2,base_channels*4,  p_drop=0.2)\n",
        "        self.conv4 = conv_block(base_channels*4,base_channels*8,  p_drop=0.2)\n",
        "        self.conv5 = conv_block(base_channels*8,base_channels*8,  p_drop=0.2)\n",
        "        self.pool  = nn.MaxPool2d(2)\n",
        "\n",
        "        # Weather projection & transformer (unchanged)…\n",
        "        self.weather_proj   = nn.Linear(weather_dim, trans_dim)\n",
        "        self.bottleneck_proj = nn.Conv2d(base_channels*8, trans_dim, 1)\n",
        "        self.pos_embed       = nn.Parameter(torch.zeros(1, 14*14, trans_dim))\n",
        "        self.weather_token   = nn.Parameter(torch.zeros(1,1,trans_dim))\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=trans_dim, nhead=num_heads,\n",
        "            dim_feedforward=trans_dim*4, dropout=0.1, batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=trans_layers)\n",
        "\n",
        "        # Decoder upsample & convs (unchanged)…\n",
        "        self.up4 = nn.ConvTranspose2d(trans_dim,     base_channels*8, 2,2)\n",
        "        self.up3 = nn.ConvTranspose2d(base_channels*8, base_channels*4, 2,2)\n",
        "        self.up2 = nn.ConvTranspose2d(base_channels*4, base_channels*2, 2,2)\n",
        "        self.up1 = nn.ConvTranspose2d(base_channels*2, base_channels,   2,2)\n",
        "        self.dec4 = conv_block(base_channels*8 + base_channels*8, base_channels*8, p_drop=0.2)\n",
        "        self.dec3 = conv_block(base_channels*4 + base_channels*4, base_channels*4, p_drop=0.2)\n",
        "        self.dec2 = conv_block(base_channels*2 + base_channels*2, base_channels*2, p_drop=0.2)\n",
        "        self.dec1 = conv_block(base_channels   + base_channels,   base_channels,   p_drop=0.2)\n",
        "        self.final_conv = nn.Conv2d(base_channels, 1, 1)\n",
        "\n",
        "    def forward(self, x, weather):\n",
        "        # same forward as before…\n",
        "        B,C,H,W = x.shape\n",
        "        e1 = self.conv1(x)\n",
        "        e2 = self.conv2(self.pool(e1))\n",
        "        e3 = self.conv3(self.pool(e2))\n",
        "        e4 = self.conv4(self.pool(e3))\n",
        "        e5 = self.conv5(self.pool(e4))\n",
        "\n",
        "        bt      = self.bottleneck_proj(e5)\n",
        "        N       = bt.shape[2]*bt.shape[3]\n",
        "        bt_flat = bt.view(B, bt.shape[1], N).permute(0,2,1)\n",
        "        bt_pos  = bt_flat + self.pos_embed[:, :N, :]\n",
        "        w_tok   = self.weather_proj(weather).unsqueeze(1) + self.weather_token\n",
        "        trans   = torch.cat([bt_pos, w_tok], dim=1)\n",
        "        out_t   = self.transformer(trans)\n",
        "        spat    = out_t[:, :-1, :]\n",
        "        fs      = int(math.sqrt(spat.size(1)))\n",
        "        f_ts    = spat.permute(0,2,1).view(B, bt.shape[1], fs, fs)\n",
        "\n",
        "        d4 = self.dec4(torch.cat([self.up4(f_ts), e4], dim=1))\n",
        "        d3 = self.dec3(torch.cat([self.up3(d4),  e3], dim=1))\n",
        "        d2 = self.dec2(torch.cat([self.up2(d3),  e2], dim=1))\n",
        "        d1 = self.dec1(torch.cat([self.up1(d2),  e1], dim=1))\n",
        "        return self.final_conv(d1)\n"
      ],
      "metadata": {
        "id": "3ILNDJ8hEjml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define which meteorological columns to pull\n",
        "weather_cols = [\n",
        "    \"air_temp_C\",\n",
        "    \"dew_point_C\",\n",
        "    \"relative_humidity_percent\",\n",
        "    \"wind_speed_m_s\",\n",
        "    \"precipitation_in\",\n",
        "]"
      ],
      "metadata": {
        "id": "n_6mX_TmEtZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/PatchedOutput/tiff_with_meteo.csv\")\n",
        "for col in weather_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "df = df.dropna(subset=weather_cols + [\"filename\"]).reset_index(drop=True)\n",
        "\n",
        "patches_dir = \"/content/drive/MyDrive/PatchedOutput_Cleaned\"\n",
        "dataset     = LSTDataset(df, patches_dir, weather_cols)\n",
        "train_sz    = int(0.8 * len(dataset))\n",
        "val_sz      = len(dataset) - train_sz\n",
        "train_ds, val_ds = random_split(dataset, [train_sz, val_sz])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  num_workers=0, pin_memory=False)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, num_workers=0, pin_memory=False)"
      ],
      "metadata": {
        "id": "b9e7XYZOEtBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 5: INITIALIZE MODEL, SmoothL1Loss, OPTIMIZER & LR SCHEDULER ─────────\n",
        "device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model     = ViTUNet(in_channels=3, weather_dim=len(weather_cols)).to(device)\n",
        "\n",
        "# Use SmoothL1 (Huber) loss instead of MSE\n",
        "loss_fn = nn.SmoothL1Loss()\n",
        "\n",
        "# Optimizer: only on parameters that require grad\n",
        "opt = torch.optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-2\n",
        ")\n",
        "\n",
        "# Reduce LR on plateau of validation loss\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    opt,\n",
        "    mode='min',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "scaler = GradScaler()\n",
        "\n",
        "print(\"✅ Model, SmoothL1Loss, optimizer & scheduler ready\")\n"
      ],
      "metadata": {
        "id": "EiXE5FV5EoWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 6: TRAIN & VALIDATE WITH EARLY STOPPING ──────────────────────────────\n",
        "import warnings\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=FutureWarning,\n",
        "    module=\"torch\\\\.cuda\\\\.amp\"\n",
        ")\n",
        "\n",
        "patience           = 5\n",
        "best_val           = float('inf')\n",
        "epochs_no_improve  = 0\n",
        "num_epochs         = 10\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    # —— Training ——\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_bar  = tqdm(train_loader, desc=f\"Epoch {epoch:02d} ▶ Train\", leave=False)\n",
        "    for imgs, weather, masks in train_bar:\n",
        "        imgs, weather, masks = imgs.to(device), weather.to(device), masks.to(device)\n",
        "        opt.zero_grad()\n",
        "        with torch.amp.autocast(device_type=\"cuda\"):\n",
        "            preds = model(imgs, weather)\n",
        "            loss  = loss_fn(preds, masks)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item() * imgs.size(0)\n",
        "        train_bar.set_postfix(smoothl1=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_train = train_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch:02d} ▶ Train SmoothL1: {avg_train:.4f}\")\n",
        "\n",
        "    # —— Validation ——\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_bar  = tqdm(val_loader, desc=f\"Epoch {epoch:02d} ▶ Val  \", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for imgs, weather, masks in val_bar:\n",
        "            imgs, weather, masks = imgs.to(device), weather.to(device), masks.to(device)\n",
        "            with torch.amp.autocast(device_type=\"cuda\"):\n",
        "                preds = model(imgs, weather)\n",
        "                loss  = loss_fn(preds, masks)\n",
        "\n",
        "            val_loss += loss.item() * imgs.size(0)\n",
        "            val_bar.set_postfix(smoothl1=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_val = val_loss / len(val_loader.dataset)\n",
        "    print(f\"           Val   SmoothL1: {avg_val:.4f}\\n\")\n",
        "\n",
        "    # Scheduler step and early stopping\n",
        "    scheduler.step(avg_val)\n",
        "    if avg_val < best_val:\n",
        "        best_val          = avg_val\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"↳ Early stopping at epoch {epoch}\")\n",
        "            break\n"
      ],
      "metadata": {
        "id": "iAmUZTw1ElCQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}